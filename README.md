# Welcome to My Convex Optimization
***
Welcome to my Convex Optimization project! This project focuses on understanding and implementing convex optimization techniques, particularly exploring various methods for finding the minimum of a convex function. Additionally, the project delves into the impact of the learning rate on the efficiency of the gradient descent algorithm.

## Task
What is the problem? And where is the challenge?
The primary goal is to comprehend convex optimization concepts and apply gradient descent methods to solve optimization problems. The challenge lies in effectively finding the minimum of a convex function and optimizing the learning rate for gradient descent.

## Description
How have you solved the problem?

To solve the problem, I have implemented several functions:

1. **print_a_function(f, values):**
   - This function plots a given function with the provided values.

2. **find_root_bisection(f, min, max):**
   - Utilizes the dichotomous algorithm (bisection method) to find the zero of a function within a given range.

3. **find_root_newton_raphson(f, f_deriv):**
   - Applies the Newton-Raphson's method to find the zero of a function.

4. **gradient_descent(f, f_prime, start, learning_rate=0.1):**
   - Performs gradient descent to find the minimum of a function.

5. **solve_linear_problem(A, b, c):**
   - Solves a linear problem using the simplex method.

## Installation
To install the project, follow these steps:

```
npm install
```

## Usage
To run the project, use the following command:

```
./my_project argument1 argument2
```

### The Core Team
<span><i>Made at <a href='https://qwasar.io'>Qwasar SV -- Software Engineering School</a></i></span>
<span><img alt='Qwasar SV -- Software Engineering School's Logo' src='https://storage.googleapis.com/qwasar-public/qwasar-logo_50x50.png' width='20px'></span>